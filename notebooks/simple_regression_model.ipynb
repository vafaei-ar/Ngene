{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gf/packages/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import ngene as ng\n",
    "import pylab as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 10, 15, 1) (13,)\n"
     ]
    }
   ],
   "source": [
    "nx,ny,n_channel = 10,15,1\n",
    "\n",
    "def data(n):\n",
    "    x = []\n",
    "    for i in range(n):\n",
    "        st = np.random.uniform(0,3)\n",
    "        x.append(np.random.normal(0,st,(nx,ny)))\n",
    "    return np.expand_dims(np.array(x),axis=-1)\n",
    "\n",
    "def truth(x,noise=0):\n",
    "    return np.std(x,axis=(1,2,3))\n",
    "\n",
    "def data_provider(n):\n",
    "    x = data(n)\n",
    "    y = truth(x)\n",
    "    return x,y\n",
    "\n",
    "x,y = data_provider(13)\n",
    "\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"act_1:0\", shape=(?, 10, 15, 12), dtype=float32)\n",
      "Tensor(\"act_2:0\", shape=(?, 10, 15, 12), dtype=float32)\n",
      "Tensor(\"act_3:0\", shape=(?, 10, 15, 1), dtype=float32)\n",
      "Tensor(\"Flatten/flatten/Reshape:0\", shape=(?, 150), dtype=float32)\n",
      "Tensor(\"dense/Relu:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"dense_1/Relu:0\", shape=(?, 1), dtype=float32)\n",
      "# of variables: 5796\n"
     ]
    }
   ],
   "source": [
    "def architecture(x_in):\n",
    "\n",
    "    initzer = tf.contrib.layers.xavier_initializer()\n",
    "    # initzer = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "    x = tf.layers.conv2d(x_in,filters=12,\n",
    "                        kernel_size=5,\n",
    "                        padding='SAME',\n",
    "                        kernel_initializer=initzer,\n",
    "                        kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=0.05),\n",
    "                        bias_initializer=tf.constant_initializer(0.1),\n",
    "                        name='conv_1')\n",
    "    x = tf.layers.batch_normalization(x,name='norm_1')\n",
    "    x = tf.nn.relu(x,name='act_1')\n",
    "    print(x)\n",
    "\n",
    "    x = tf.layers.conv2d(x,filters=12,\n",
    "                        kernel_size=5,\n",
    "                        padding='SAME',\n",
    "                        kernel_initializer=initzer,\n",
    "                        kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=0.05),\n",
    "                        bias_initializer=tf.constant_initializer(0.1),\n",
    "                        name='conv_2')\n",
    "    x = tf.layers.batch_normalization(x,name='norm_2')\n",
    "    x = tf.nn.relu(x,name='act_2')\n",
    "    print(x)\n",
    "\n",
    "    x = tf.layers.conv2d(x,filters=1,\n",
    "                        kernel_size=5,\n",
    "                        padding='SAME',\n",
    "                        kernel_initializer=initzer,\n",
    "                        kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=0.05),\n",
    "                        bias_initializer=tf.constant_initializer(0.1),\n",
    "                        name='conv_3')\n",
    "    x = tf.layers.batch_normalization(x,name='norm_3')\n",
    "    x = tf.nn.relu(x,name='act_3')\n",
    "    print(x)\n",
    "    \n",
    "    x = tf.contrib.layers.flatten(x)\n",
    "    print(x)\n",
    "    x = tf.layers.dense(x, 10 , activation=tf.nn.relu)\n",
    "    print(x)\n",
    "    y_out = tf.layers.dense(x, 1 ,activation=tf.nn.relu)\n",
    "    print(y_out)\n",
    "    \n",
    "    return y_out\n",
    "\n",
    "def loss(y_true,x_out):\n",
    "    return tf.reduce_mean(tf.pow(tf.log(y_true+1) - tf.log(x_out+1), 2))\n",
    "def loss(y_true,x_out):\n",
    "    return tf.reduce_mean(tf.pow(y_true - x_out, 2))\n",
    "model = ng.Model(data_provider,\n",
    "         restore=False,model_add='./model',arch=architecture, loss = loss)\n",
    "print('# of variables:',model.n_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, cost= 0.200078\n",
      "Epoch:1, cost= 0.146362\n",
      "Epoch:2, cost= 0.146524\n",
      "Epoch:3, cost= 0.145938\n",
      "Epoch:4, cost= 0.145314\n",
      "Epoch:5, cost= 0.145632\n",
      "Epoch:6, cost= 0.147412\n",
      "Epoch:7, cost= 0.148026\n",
      "Epoch:8, cost= 0.145958\n",
      "Epoch:9, cost= 0.146178\n"
     ]
    }
   ],
   "source": [
    "model.train(data_provider=data_provider,training_epochs = 10,iterations=200 ,n_s = 127,\n",
    "                    learning_rate = 0.01, time_limit=None,\n",
    "                    metric=None, verbose=1,death_preliminary_check = 30,\n",
    "                    death_frequency_check = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data_provider(10)\n",
    "y_pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99523418, 0.96065788, 1.00919752, 1.03694964, 1.02378892,\n",
       "       0.97705924, 1.06203717, 1.07212357, 0.94614618, 0.94411107])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9855635],\n",
       "       [0.9855635],\n",
       "       [0.9855635],\n",
       "       [0.9855635],\n",
       "       [0.9855635],\n",
       "       [0.9855635],\n",
       "       [0.9855635],\n",
       "       [0.9855635],\n",
       "       [0.9855635],\n",
       "       [0.9855635]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
